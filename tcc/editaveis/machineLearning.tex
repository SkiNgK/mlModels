\chapter{Aprendizado de Máquina}
\section{Definição}
A AM é considerado uma disciplina dentro da inteligência artificial, com foco na construção de softwares computacionais dotados da capacidade de aprender autonomamente \cite{Hosch}. Essa disciplina trabalha com o estudo e a construção de algoritmos, capazes de aprender com seus “erros” no reconhecimento de dados e realizarem previsões sobre novos dados. Esses algoritmos de indução são considerados um grande passo na descoberta do conhecimento \cite{Kohavi}.

Apesar da complexidade em AM, essa disciplina pode ser contextualizada de maneira mais geral como o campo de estudo que dá ao computador a habilidade de aprender sem ser explicitamente programado \cite{Arthur}, porém uma visão mais orientada para a área da engenharia, que segundo \citeonline{Tom}, é dito que um programa de computador aprende com a experiência \textbf{\textit{E}} em relação a alguma tarefa \textbf{\textit{T}} e alguma medida de desempenho \textbf{\textit{P}}, se seu desempenho em \textbf{\textit{T}} e medido por \textbf{\textit{P}} melhora com a experiência \textbf{\textit{E}}.

\section{Aplicações em Aprendizado de Máquina}
O AM serve de auxílio para diversos contextos de naturezas diferentes. Sendo assim, a AM consegue auxiliar com o uso dos dados coletados a melhor decisão de um negócio, por exemplo, uma possível aplicação de um modelo de AM é predizer qual a probabilidade de um cliente comprar um determinado produto com base no seu histórico de compras passadas \cite{Amazon}.

Na saúde, AM é uma tendência crescente na indústria médica, graças ao advento de dispositivos eletrônicos como sensores, que podem acessar os dados de pacientes em tempo real. A tecnologia também pode ajudar médicos a analisar os dados para identificar tendências ou alertas, consequentemente, levando ao aperfeiçoamento de diagnósticos e tratamentos \cite{Sas}.

\section{Funcionamento de um algoritmo de AM}
Cada algoritmo tem suas peculiaridades quanto ao seu funcionamento. Entretanto esses algoritmos em seu estado mais básico trabalham com a entrada de dados num sistema, que processa os mesmos utilizando um modelo de predição geralmente já postulado, no qual derivam um resultado com base em uma predição que o modelo fez sobre os dados de entrada. Esses algoritmos possuem alguns métodos e técnicas para validar seu funcionamento, por exemplo, declarando uma dada porcentagem para avaliar o grau da acurácia de seu resultado, permitindo assim verificar se a predição gerada pelo algoritmo se aproxima do resultado esperado no contexto real. Sendo essa e outras situações melhor contextualizado neste capítulo.

Considerando ainda que o AM, com seu foco na predição no desenvolvimento de algoritmos capazes de aprender com seus erros, essa disciplina é muito atrelada a otimização matemática. Possuindo como uma de suas principais características, a utilização de métodos estatísticos para validar o seu funcionamento \cite{trevor2009elements}.

\section{Tipos de Aprendizado}
Os algoritmos são classificados quanto ao seu tipo de aprendizado. Existem três categorias, as quais se distinguem de acordo com a natureza do comportamento no tratamento dos dados. Estas categorias são aprendizado supervisionado, não supervisionado e por reforço \cite{geron2017hands}.
 
\subsection{Aprendizado Supervisionado}
O objetivo principal do aprendizado supervisionado é ensinar um modelo através de uma base de treino etiquetada, que permite fazer predições de dados futuros. O termo supervisionado se refere a um grupo de dados onde a “resposta”, sinal ou valor esperado já é conhecido. Este valor é conhecido como etiqueta e é utilizada para verificar se o algoritmo identificou corretamente os dados durante o treinamento. As tarefas do aprendizado supervisionado podem ser divididas em classificação e regressão, onde a classificação tem as etiquetas esperadas com um valor fixo, por exemplo, uma avaliação binária, e a regressão é referente a um sinal com valor contínuo, como uma regressão polinomial \cite{geron2017hands}, ou segundo \citeonline{kirk2014thoughtful}, a regressão é ajustar o conjunto de dados á uma função qualquer.

Exemplos de algoritmos existentes \cite{lorena2007introduccao}; \cite{kirk2014thoughtful}; \cite{murthy1998automatic} \cite{ho1995random}:

\begin{itemize}
    \item \textbf{KNN}: Determina o rótulo de classificação de um dado baseando nos valores das amostras vizinhas mais próximos;
    \item \textbf{\textit{Decision Trees}}: é uma forma de organizar regras referentes a dados com estruturas hierárquicas e sequências, que particionam estes dados recursivamente;
    \item \textbf{SVM}: separado em linear e não linear, consiste na separação de dados de um conjunto maior em classes de conjuntos mais restritos.
    \item \textbf{RF}: são um método de aprendizado conjunto para classificação, regressão e outras tarefas, que operam construindo uma multiplicidade de árvores de decisão no momento do treinamento e gerando a classe que é o modo das classes ou previsão média das árvores individuais.
\end{itemize}

\subsection{Aprendizado não-supervisionado}
Ao contrário do aprendizado supervisionado, os dados não estão etiquetados ou até mesmo possuem uma estrutura desconhecida. Utilizando as técnicas do aprendizado não supervisionado é possível explorar a estrutura para extrair informações necessárias dos dados sem a orientação de uma variável de resultado conhecida ou uma função de recompensa \cite{geron2017hands}.

Exemplos de algoritmos existentes \cite{kirk2014thoughtful}:
\begin{itemize}
    \item  \textbf{\textit{Clustering}}: É utilizado para agrupar padrões, ou melhor, no treinamento é introduzido um conjunto de dados e o algoritmo procura relações entre eles agrupando tais dados em grupos por grau de semelhança, na predição, com um novo dado inserido o algoritmo busca padrões existentes nele e cataloga-o no respectivo grupo;   
    \item  \textbf{\textit{Collaborative Filtering}}: É utilizado no desenvolvimento de sistemas de recomendação, basicamente utiliza informações cruzadas dos usuários para predizer gostos em comum, por exemplo se você compra bastante cerveja em um site de compras, o sistema recomendará cerveja para você, caso um grupo significante de usuários compre cerveja e carvão, o sistema recomendará conjuntamente o carvão.
\end{itemize}

\subsection{Aprendizado por reforço}
Utiliza um sistema de recompensas para reforçar a continuidade de um comportamento esperado, por exemplo, um jogo onde o personagem é beneficiado com uma recompensa sempre que atinge um golpe no adversário, quanto mais forte for o golpe maior a recompensa. Deste modo, o modelo memoriza quais os comandos geraram as maiores recompensas \cite{kirk2014thoughtful}.

\section{\textit{Feature}} 
Uma \textit{feature} é uma característica ou variável do problema, que pode ser processada pelo modelo e gerar um resultado condizente com a realidade. Deve ser mensurável e independente, sendo que uma \textit{feature} é a base para o funcionamento dos algoritmos de classificação, regressão e reconhecimento de padrões. Normalmente, é um número mas pode ser uma palavra, grafo, vetor, dentre outros. \cite{chandrashekar2014survey}.

Outro conceito importante sobre AMs, é a \textbf{redução de dimensionalidade}, muito utilizada em estatística, refere-se ao processo de diminuição do número de variáveis aleatórias, selecionando um subconjunto com variáveis relevantes. Serve, dentre outras funcionalidades, para transformar o processo de aprendizado mais eficiente \cite{borges2006reduccao}. Isto ocorre devido a modelos com um número elevado de variáveis ocasionam em um maior tempo de computação e um baixo desempenho da previsão \cite{chandrashekar2014survey}.

Um exemplo de  tecnica de redução de dimensionalidade é a PCA (sigla do inglês: \textit{Principal Component Analysis}, Análise de Componentes Principais), sendo esta uma das tecnicas mais difundidas na redução de dimenção.

\subsection{PCA}
A PCA possibilita reduzir consideravelmente o número de variáveis disponíveis, além de, eliminar sobreposições e escolher formas mais representativas do conjunto de dados original, por meio de combinações lineares ortogonais das variáveis originais, para um novo sistema de coordenadas \cite{jolliffe2011principal}.

\section{Desafios do Aprendizado de Máquinas}
Em um projeto de AM, existem diversos aspectos que podem levar a um péssimo resultado ou problemas na execução do mesmo. Em resumo, a tarefa principal do AM é a seleção de um algoritmo, ou modelo, e treiná-lo utilizando algum tipo de dado. Logo, ao analisar os problemas provenientes de um resultado ineficiente, pode-se encontrar principalmente duas origens para o problema a escolha de um “algoritmo ruim” ou “dados ruins” \cite{geron2017hands}.

O conceito de “dados ruins”, não deve ser considerado ao pé da letra, sendo um pouco mais complexo, envolvendo principalmente a coleta destes e tratamento associado. Para exemplificar,  pode-se listar alguns exemplos retirados de \citeonline{geron2017hands}:

\begin{itemize}
    \item \textbf{Quantidade insuficiente de dados de treino}: Para um funcionamento pleno de um sistema de AMs é necessária uma grande quantidade de dados, alguns problemas necessitam de uma alta quantidade de dados para funcionar corretamente, como no reconhecimento de imagens.
    \item \textbf{Dados não representativos}: Com o intuito de alcançar a boa generalização, é crucial que os dados de treino sejam representativos em relação ao escopo dos dados.
    \item \textbf{Dados de baixa qualidade}: É evidente que caso os dados de treinos tenham muitos erros e ruídos, originados de um péssimo processo de coleta, isso irá dificultar o sistema na detectação de padrões necessários ou até mesmo alcançar o mínimo de performance requerido.
    \item \textbf{\textit{Features}  irrelevantes}: Seguindo a lógica por trás da expressão \textit{garbage-in garbage-out} (termo em inglês: Lixo entra e lixo sai), o sistema apenas será capaz de gerar bons resultados caso exista dados contendo o suficiente de \textit{features} relevantes ao invés das não relevantes, ou seja, \textit{features} irrelevantes podem conduzir o programa a uma baixa precisão.
\end{itemize}

Com relação a “algoritmo ruim”, também não deve ser interpretado literalmente, ou seja, um “algoritmo ruim” pode ser proveniente da escolha de um modelo de algoritmo para tratar um problema no qual o algoritmo não foi otimizado para solucionar. Exitem dois principais problemas associados ao manejo de um algoritmo, sendo eles \cite{geron2017hands}:

\begin{itemize}
    \item \textbf{\textit{Overfitting} dos dados de treino}: \textit{Overfitting} acontece quando o modelo apresenta uma boa performance na sua base de treino, mas não generaliza muito bem, ou seja, o modelo pode ser considerado “viciado”, é um erro bem comum ocorrendo no treinamento do modelo. Por exemplo, uma amostragem com muito ruído pode encontrar algum padrão no próprio ruído e generalizar para o mesmo, não generalizando para novos dados.
    \item \textbf{\textit{Underfitting} dos dados de treino}: Ao contrário do \textit{Overfitting}, \textit{Underfitting} acontece quando o modelo é muito simples para ser utilizado com a estrutura de dados selecionada, resultando em um modelo impreciso para ser utilizado no mundo real. Isto devido aos dados reais serem provavelmente mais complexos que os utilizados no treinamento do modelo.
\end{itemize}

\section{Ferramentas}
\label{sec:MAFerramentas}
Existem diversas ferramentas para auxiliar o desenvolvimento em AM, sendo que atualmente \textit{Python} é uma das linguagens mais utilizadas nesse seguimento. Segundo \citeonline{senders2017machine}, essa utilização é devido ao conjunto bem eficiente de bibliotecas disponíveis, o fato de ser de código aberto, a facilidade de plotar gráficos e demais esquemas de visualização, além da simplicidade de identificar erros no \textit{software}, tornam a linguagem \textit{Python} uma boa indicação para trabalhar com AM.

Algumas ferramentas amplamente utilizadas em AM, podem ser elucidadas a seguir \cite{scikitlearn}; \cite{abadi2016tensorflow}; \cite{McKinney2012datapython}:
\begin{itemize}
    \item \textbf{\textit{Scikit-learn}}: Possui uma ampla gama de algoritmos, com uma alta facilidade de uso, boa documentação e uma API(sigla do Inglês: \textit{Application Programming Interface}, Interface de Programação de Aplicação) amplamente consistente. A API é um conjunto de funções que são utilizados para facilitar o desenvolvimento de um \textit{software};
    \item \textbf{\textit{TensorFlow}}: Projetado pelo Google para operar em larga escala, utiliza ferramentas avançadas sendo utilizado inclusive pelo próprio Google;
    \item \textbf{\textit{Keras}}: API de alto nível com foco em RNAs (Redes Neurais Artificiais);
    \item \textbf{\textit{Matplotlib}}: Ferramenta para a criação de gráficos;
    \item \textbf{\textit{Numpy}}: Utilizada para manipulações matemáticas complexas, como multiplicação de matrizes, entre outras;
    \item \textbf{\textit{Jupyter Notebook}}: aplicativo que permite a criação de códigos em \textit{Python} de modo interativo;
    \item \textbf{\textit{Pandas}}: Ferramenta para estruturar dados, tornando o trabalho com dados “relacionais” ou “rotulados” mais fácil e intuitivo. Ideal para trabalhar com matrizes.
\end{itemize}

\section{Visualizar a solução}
Construir visualizações informativas são umas das mais importantes tarefas dentro da análise de dados \cite{McKinney2012datapython}. Essa etapa consiste na utilização de ferramentas e técnicas para a representação dos dados obtidos tanto pelo modelo quanto pelos dados coletados para validação dos mesmos. O resultados obtidos pelo algoritmo de AM sobre os dados de coleta seram aferidos quanto ao seu \textit{benchmarking} \cite{Benchmarking} para avaliar o seu desempenho, análise de acurácia e precisão como também para avaliar seu tempo de resposta. A apresentação dos dados da coleta tem por objetivo avaliar tanto a separação do espaço amostral dos dados quanto para se obter um comparativo que melhor represente de maneira visual os dados após a filtragem da etapa do processamento dos dados, de maneira geral serve para ajudar a identificar \textit{outliers} ou transformações de dados necessárias ou como uma forma de gerar ideias para modelos \cite{McKinney2012datapython}.

\subsection{Matriz de Confusão}
\label{sc:matrizconsusao}
Um dos métodos mais utilizadas para apresentar a solução do modelo é a matriz de confusão. Uma matriz de confusão, é um método para visualizar graficamente a eficiência de um modelo de AM. Onde, realiza-se o cruzamento entre os valores esperados com os valores alcançados pelo algoritmo \cite{caelen2017bayesian}. Por exemplo na Figura \ref{matriz_consusao}, existem três tipos de flores e o algoritmo, no caso o SVM, deveria classificar os dados de entradas em um destes três grupos. Como observado, existiam 13 dados do tipo “setosa”, e o SVM acertou todos os 13. O mesmo ocorre com os dados do tipo “virginica”, onde ocorreu 100\% de acerto. Porém, nos dados do tipo “versicolor” existiam 16 amostras, e o SVM acertou 10 e errou os outros 6 restantes, já que o valor alcançado nestes 6 dados foi de “virginica”.

\begin{figure}[!htb]
	\centering
    \includegraphics[width=1.1\textwidth]{figuras/ma_normalizedy.eps}
    \caption{Ilustração da matriz de confusão, adaptado de \cite{scikitlearn}}
	\label{matriz_consusao}
\end{figure}

\section{Validação cruzada}
\label{sc:crossvalidation}
A validação cruzada ou \textit{Cross-Validation} é uma técnica para verificar o quão eficiente é a capacidade de generalização do modelo. Ou seja, qual o desempenho do modelo ao prever um novo conjunto de dados. Com a validação cruzada evita-se o \textit{overfitting}, além de auxiliar no ajuste dos parâmetros do algoritmo \cite{james2013introduction}. A validação cruzada consiste em \cite{james2013introduction} e \cite{raschka2015python}:

\begin{enumerate}
    \item Separar aleatoriamente o conjunto de dados em três partes (treino, teste e validação);
    \item O conjunto de dados de treino é utilizado para treinar o modelo;
    \item O conjunto de validação é utilizado para ajustar os parâmetros. Isto é, após o treino verifica-se a precisão do modelo e caso não atinga a expectativa, realiza-se os ajustes necessários no algoritmo. Após, realiza-se um novo treinamento com os dados de teste;
    \item Ao final, verifica-se a generalização do algoritmo treinado, utilizando o conjunto de validação. Deste modo, o conjunto de validação é utilizada apenas uma vez no processo de AM.
\end{enumerate}

A validação cruzada possue ainda algumas variações, sendo elas: \textit{holdout cross-validation}, \textit{k-Fold Cross-Validation} e \textit{Leave-one-out cross-validation (LOOCV)}.


\subsection{\textit{Holdout Cross-Validation}}
Modelo clássico da validação cruzada, consiste em separar os dados em dois conjuntos mutualmente exclusivos (treino e validação), porém essa abordagem acaba não sendo eficiente, por aumentar a probabilidade de \textit{overfitting}, para uma maior eficiência, utiliza-se a variações com os três conjuntos explicados anteriormente \cite{raschka2015python}.

\subsection{\textit{k-Fold Cross-Validation}}
No \textit{k-fold} divide-se o conjunto total de dados em \textbf{\textit{k}} subconjuntos mutualmente exclusivos, com a mesma quantidade de dados, um destes subconjuntos é utilizado para teste e os outros \textbf{\textit{k-1}} restantes são utilizados no treinamento do modelo com os devidos ajuste de parâmetros necessários, tal processo é repetido \textbf{\textit{k}} vezes, alternando o conjunto de teste nestas iterações. Após as \textbf{\textit{k}} iterações, se calcula a média do erro esperado \cite{scikitlearn}. A Figura \ref{kfold} ilustra este método.

\subsection{\textit{Leave-One-Out Cross-Validation (LOOCV)}} Uma variação do \textit{k-fold}, com \textbf{\textit{k}} igual ao total de dados de entrada \textbf{\textit{N}}. Possue um alto custo operacional.

\begin{figure}[!htb]
    \centering
     \includegraphics[width=1\textwidth]{figuras/kfold.eps}
     \caption{Ilustração do \textit{k-fold}, adaptado de \citeonline{raschka2015python}.}
     \label{kfold}
\end{figure}

As seções seguintes descrevem os principais algoritmos de AM utilizados em classificação, segundo \citeonline{scikitlearn}, sendo eles:
\begin{itemize}
    \item SVM;
    \item \textit{Random forest};
    \item K Vizinhos Mais Próximos.
\end{itemize}

\section{SVM}

A SVM é um dos modelos mais populares em AMs, sendo composto por um conjunto de métodos de aprendizado supervisionada. Pode ser utilizada para classificação, regressão ou \textit{outlier detection} \cite{scikitlearn}. Segundo \citeonline{braga2000redes} e \citeonline{haykin1999neural}, os resultados da aplicação de SVM são comparáveis e muitas vezes superiores aos obtidos por outros algoritmos de aprendizado, como as RNAs. Exemplos de aplicações de sucesso podem ser encontrados em diversos domínios, como na categorização de textos,  catalogação de imagens \cite{pontil1998support}, e em Bioinformática \cite{noble2004support}.

As SVMs são divididas em dois grupos, categorizadas conforme o estado dados a serem resolvidos, ou seja é um problema linear ou não \cite{lorena2007introduccao}.

Segundo \citeonline{scikitlearn}, as principais vantagens em SVMs são:

\begin{itemize}
    \item sua eficácia em grandes espaços dimensionais ou quando o numero de dimensões supera o de amostras;
    \item a eficiência em termo de memória;
    \item a versátilidade: possui diferentes tipos de funções de \textit{kernel} (linear, polinomial, sigmoide e RBF (sigla do inglês: \textit{radial basis function}, função de base radial), possibilita também a utilização de um \textit{kernel} customizado, ou seja, uma função matemática classificação personalizada. A Figura \ref{svmkernel} exemplifica algumas funções de \textit{kernel}, onde os dados são classificados em três grupos distintos.
\end{itemize}

\begin{figure}[!htb]
    \centering
     \includegraphics[width=0.9\textwidth]{figuras/svmkernel.eps}
     \caption{SVMs utilizando \textit{kernel} diferentes, adaptado de \citeonline{scikitlearn}.}
     \label{svmkernel}
 \end{figure}

 A SVM funciona no princípio de separação ótima entre classes. Ou seja, com base nas amostras de treinamento, cria-se uma distribuição de probabilidade, remove-se algumas amostras de modo iterativo e calcula-se novamente a distribuição de probabilidade, continuando este ciclo até estabelecer os vetores de suporte em um hiperplano ou em um conjuntos de hiperplanos. Estes vetores de suporte, são os pontos que definem a maior margem possível entre as classes \cite{huang2002assessment}. A Figura \ref{svm_hiperplano} exemplifica estes conceitos.

 \begin{figure}[!htb]
     \centering
     \includegraphics[width=0.9\textwidth]{figuras/svm_hiperplano.eps}
     \caption{Esquematização de um SVM, adaptado de \citeonline{scikitlearn}.}
     \label{svm_hiperplano}
 \end{figure}

 \subsection{Funcionamento}

As SVMs foram desenvolvidas por \citeonline{vapnik1998statistical}, no âmbito da Teoria Estatística da Aprendizagem, logo para entender o funcionamento do dado modelo é necessário entender o próprio \textit{framework} da Teoria Estatística da Aprendizagem \cite{vapnik1998statistical}. Porém como o foco neste trabalho é a aplicação do modelo, não será abordado de maneira aprofundada o conceito da Teoria Estatística da Aprendizagem, cujo o foco é a implementação.
 

Em sua formulação mais geral, a SVM encontra um hiperplano em um espaço diferente daquele dos dados de entrada \textbf{\textit{X}}. É um hiperplano, em um espaço de característica induzido por um  \textit{kernel} \textbf{\textit{K}}. Através do  \textit{kernel} \textbf{\textit{K}}, o espaço de hipóteses é definido como um conjunto de  “hiperplanos” no espaço de feições induzido por \textbf{\textit{K}}. Isso também pode ser visto como um conjunto de funções em um EHR (Espaço Hilbert de Reprodução) definido por \textbf{\textit{K}} \cite{wahba1990spline} \cite{vapnik1998statistical}. Para resumir, o espaço de hipóteses usado pela SVM é um subconjunto do conjunto de hiperplanos definido em algum espaço de um EHR. Este espaço pode ser formalmente escrito como na Equação \ref{eq:leftleft}.


\begin{equation} \label{eq:leftleft}
    \left \{ f:\left \| f \right \|_{2}^{k} < \infty \right \}
\end{equation}



Onde \textbf{\textit{K}} é o kernel que define o EHR, e $ \left \| f \right \|_{2}^{k} $  é a norma EHR da função \cite{wahba1990spline}. 


A SVM considera os conjuntos da forma da Equação \ref{eq:forma} para alguma constante \textbf{\textit{A}}. Na estrutura da Teoria Estatística de Aprendizagem, a constante \textbf{\textit{A}} é usada para definir uma estrutura de espaços de hipóteses (o quanto maior for, mais complexo é o espaço da hipótese). O objetivo da SVM é encontrar a solução com a norma EHR  “ideal”, ou seja, encontrar o \textbf{\textit{A}} ótimo \cite{evgeniou1999support}.

\begin{equation} \label{eq:forma}
    \left \{ f:\left \| f \right \|_{2}^{k} \leq A^{2} \right \}\
\end{equation}


A segunda opção retratada pelo estudo de \citeonline{evgeniou1999support} é a da função de perda. Uma função de perda é uma função que mapeia um evento ou valores de uma ou mais variáveis num número real, intuitivamente representando algum “custo” associado ao evento \cite{wald1950statistical}. O estudo \citeonline{evgeniou1999support} distingue as SVM em classificação e regressão, porém como este trabalho será focado na classificação, será apenas retratado o primeiro caso, dos classificadores SVM.


Para classificação, o erro de classificação precisa ser minimizado. Então uma função de perda do sinal na forma apresentada pela Equação \ref{eq:formaperda}, deve ser usada (na classificação \textbf{\textit{y}} toma valores binários $ \pm1 $ e a classificação é feita tomando o sinal de função $ f(x) $). No entanto, devido à escala e às razões computacionais \cite{vapnik1998statistical}, a função de perda real usada para classificação SVM é, Equação \ref{eq:formaperdaSVM}. Ou seja, caso a função de perda seja 0, temos:

\begin{equation} \label{eq:perda0}
    |1-yf(x)|< 0  
\end{equation}

caso contrário temos:

\begin{equation} \label{eq:perda1}
    |1-yf(x)|> 0   
\end{equation}

Isso também é chamado de função de perda de  “margem flexível” por causa de sua interpretação padrão de “margem”: os pontos para os quais a função de perda é zero são os que têm “margem”, descrito pela Equação \ref{eq:videSVM} \cite{evgeniou1999support}. 

\begin{equation} \label{eq:formaperda}
    -yf(x)
\end{equation}

\begin{equation} \label{eq:formaperdaSVM}
    |1-yf(x)|_{+}
\end{equation}

\begin{equation} \label{eq:videSVM}
    yf(x)/\left \| f \right \|_{k}^{2}\
\end{equation}

Para o caso da Equação \ref{eq:casoeq} e Equação \ref{eq:casoseja}. A margem é uma quantidade geométrica importante associada à classificação SVM \cite{evgeniou1999support}

\begin{equation} \label{eq:casoeq}
    1/\left \| f \right \|_{k}^{2}
\end{equation}

\begin{equation} \label{eq:casoseja}
    1-yf(x) \geq  0 \Rightarrow yf(x)/\left \| f \right \|_{k}^{2} \geq 1/\left \| f \right \|_{k}^{2}
\end{equation}

A função para classificação em uma SVM, pode ser generalizada pela Equação \ref{eq:genSVM}:
\begin{equation} \label{eq:genSVM}
    min\left \| f \right \|_{k}^{2}+C\sum_{i=0}^{l}\left | 1-y_{i}f(x_{i})\right |_{+}\
\end{equation}

\section{\textit{Random Forest}}

Desenvolvido por \citeonline{breiman2001random}, o método combina a abordagem de amostragem de Breiman, e a seleção aleatória de características, introduzida independentemente por \citeonline{ho1995random} e \citeonline{amit1997shape}, a fim de construir uma coleção de árvores de decisão, com variação controlada, Usando ensacamento, cada árvore de decisão no conjunto é construída usando uma amostra com substituição dos dados de treinamento. Estatisticamente, a amostra provavelmente terá cerca de 64\% de instâncias aparecendo pelo menos uma vez na amostra. As instâncias na amostra são referidas como instâncias de embalagem e as instâncias restantes (cerca de 36\%) são referidas como instâncias fora do pacote. Cada árvore no conjunto funciona como um classificador base para determinar o rótulo de classe de uma instância não rotulada. Isso é feito por meio de votação por maioria, em que cada classificador atribui um voto ao rótulo de classe previsto. Em seguida, o rótulo de classe com o maior número de votos é usado para classificar a instância \cite{fawagreh2014random}.

O Autor \citeonline{scikitlearn} define \textit{Random Forest} como um meta estimador que se ajusta a vários classificadores de árvore de decisão em várias subamostras do conjunto de dados e usa a média para melhorar a precisão preditiva e controlar o ajuste excessivo. O tamanho da subamostra é sempre o mesmo que o tamanho da amostra de entrada original.

\subsection{Funcionamento}

Segundo \citeonline{bastos2013proposta}, as \textit{Random Forest} são obtidas através de \textit{bootstrapping aggregating} (ou simplesmente \textit{bagging}), um método utilizado para gerar múltiplas versões de um preditor \cite{breiman1996bagging}. Tais versões são construídas a partir de amostras do conjunto original, obtidas via sorteio simples com reposição. Apresentamos a seguir a notação sugerida por \citeonline{breiman2001random}. 

Um conjunto de treinamento e denotado por $ L = {(xn, yn), n = 1, 2,...,N} $, onde $ N $  é a quantidade de exemplos, $ xn $ e o vetor de atributos e $ yn \gamma {1, 2,...,C} $ e a classe verdadeira do 50 n-ésimo exemplo. Os atributos são indexados por $ m = 1, 2,...,M $, e assim o vetor de atributos do n-ésimo exemplo é denotado por  $ xn = (xn,1, xn,2,...,xn,M) $. Denote por $ \psi (x,L) $ um preditor para a classe de $ x $ construído a partir do conjunto de treinamento L. 

Suponha que exista uma sequência finita de conjuntos de treinamento $ {L(k) }, k = 1, 2,...,K $, cada um consistindo de $ N $ observações independentes provenientes da mesma distribuição subjacente ao conjunto L. A ideia central é usar $ {L(k) } $ para obter um preditor melhor do que o preditor simples $ \psi (x,L) $, tendo como restrição utilizar apenas a sequência de preditores $ \psi (x,L(k)) $. Indexando-se as classes por $ c = 1, 2,...,C $, um método de agregar os preditores $ \psi (x,L(k)) $ e através de votação, escolhendo para x a classe mais votada entre os preditores. 

Formalmente, denotando por $ Nc = |{k \psi {1 ...K} : \psi (x,L(k) ) = c}| $ o número de “votos” na classe $ c $, o classificador agregado pode ser definido por $ \psi A(x) = arg max(c) N(c) $. O subscrito $ A $ em $ \psi A $ denota agregação. A obtenção de $ {L(k) }, k = 1, 2,...,K $ é feita tomando-se amostras \textit{bootstrap} de $ L $, via sorteio com repetição, cada qual de tamanho N. Em cada amostra de treinamento \textit{bootstrap}, aproximadamente 37\% das instâncias do conjunto original  não são utilizadas para o treinamento \cite{breiman1996bagging}.

Essas instâncias são usadas como um conjunto de teste, para estimar o erro de cada classificador e, a partir deste, o erro do classificador agregado. O erro \textit{out-of-bag} de cada classificador $ \psi (x,L(k)) $ é definido como o percentual do conjunto de teste (constituído por $ L\L(k) $) classificado erroneamente. 

Na formulação das RFs propostas por \citeonline{breiman2001random}, o algoritmo básico de construção das árvores e o CART(sigla do inglês: \textit{Classification and Regression Trees}, Classificação e Árvores de regressão)\cite{breiman2017classification}. As árvores são expandidas ao máximo, sem poda. Para a divisão de cada nó, um subconjunto de tamanho fixo dos atributos de entrada é selecionado aleatoriamente, escolhendo-se a divisão ótima dentro desse subconjunto.

\section{K Vizinhos Mais Próximos}

Segundo \citeonline{scikitlearn}, o princípio por trás dos métodos de KNN é encontrar um número pré-definido de amostras de treinamento mais próximas da distância do novo ponto e prever o rótulo a partir delas. O número de amostras pode ser uma constante definida pelo usuário (\textit{k-neighbor neighbor learning}) ou variar com base na densidade local de pontos (aprendizado de vizinho baseado em raio). A distância pode, em geral, ser qualquer medida métrica, a distância euclidiana padrão é a escolha mais comum. Os métodos baseados em vizinhos são conhecidos como métodos de aprendizado de máquina não generalizantes, já que eles simplesmente “lembram” todos os seus dados de treinamento (possivelmente transformados em uma estrutura de indexação rápida, como \textit{Ball Tree} ou \textit{KD Tree}).

Apesar de sua simplicidade, os algorítimos KNN tiveram sucesso em um grande número de problemas de classificação e regressão, incluindo dígitos manuscritos e cenas de imagens de satélite. Sendo um método não paramétrico, muitas vezes é bem-sucedido em situações de classificação em que o limite de decisão é muito irregular \cite{scikitlearn}.

\subsection{Funcionamento}

Baseando-se no autor \citeonline{peterson2009k} no qual é apresentanda a característica da distância geométrica entre amostras desse algoritimo com uma representação gráfica, a fim de detalhar o funcionamento do mesmo.

O classificador de $ k $ mais próximo do vizinho é comumente baseado na distância euclidiana entre uma amostra de teste e as amostras de treinamento especificadas. Utilizando $ x_{eu} $ como uma amostra de entrada com $ p $ características $ (x_{eu1},x_{eu2},\cdots ,x_{eup}) $ $ n $ ser o número total de amostras de entrada $ (i=1,2,\cdots,n) $ e p o número total de recursos $ (j=1,2,\cdots,p) $ . A distância euclidiana entre a amostra $ x_{i} $ e $ x_{j} $ $ (l=1,2,\cdots,n) $  é definido como:

\begin{equation} \label{eq:diseuclidiana}
    d(x_{i},x_{l})=\sqrt{(x_{i1}-x_{l1})^{2}+(x_{i2}-x_{l2})^{2}+\cdots+(x_{ip}-x_{lp})^{2}}
\end{equation}


\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{figuras/Knn_voronoi.eps}
    \caption{Tesselação de Voronoi}
    \label{voronoiEx}
\end{figure}

Uma representação gráfica do conceito de vizinho mais próximo é ilustrada na tesselação de Voronoi \cite{voronoi1907g} mostrada na Figura. \ref{voronoiEx}, na qual apresenta as células de Voronoi de 19 amostras marcadas com um "+". A tesselação de Voronoi reflete duas características do sistema de coordenadas bidimensional do exemplo:

\begin{itemize}
    \item Todos os pontos possíveis dentro da célula de Voronoi de uma amostra são os pontos vizinhos mais próximos para essa amostra.
    \item Para qualquer amostra, a amostra mais próxima é determinada pelo Voronoi mais próximo da borda da célula.
\end{itemize}

O mosaico mostra 19 amostras marcadas com um "+", e a célula de Voronoi, $ R $ ,em torno de cada amostra. Uma célula de Voronoi encapsula todos os pontos vizinhos que estão mais próximos de cada amostra e é definida como:

\begin{equation} \label{eq:celVoroniEncap}
    R_{i}= \left \{ x \epsilon R^{p}: d(x,x_{i})\leq d(x,x_{m}),\forall i\neq m\right \}
\end{equation}

Onde $ R_{i} $ é a célula de Voronoi para amostra $ x_{eu} $ , e $ x $ representa todos os pontos possíveis dentro da célula de Voronoi $ R_{i} $. Os mosaicos de Voronoi refletem principalmente duas características de um sistema de coordenadas: i) todos os pontos possíveis dentro da célula de Voronoi da amostra são os pontos vizinhos mais próximos para essa amostra e ii) para qualquer amostra, a amostra mais próxima é determinada pela borda da célula de Voronoi mais próxima. Usando a última característica, a regra de classificação de k-vizinho mais próximo é atribuir a uma amostra de teste o rótulo da categoria majoritária de suas k amostras de treinamento mais próximas. Na prática, $ k $ é geralmente escolhido para ser ímpar, de modo a evitar empates. A regra $ k = 1 $ é geralmente chamada de regra de classificação de vizinho mais próximo \cite{peterson2009k}.